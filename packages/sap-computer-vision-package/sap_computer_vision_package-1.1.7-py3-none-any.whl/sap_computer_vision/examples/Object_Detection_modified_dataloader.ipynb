{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ -d \"MeterDataset\" ] && echo \"skipping\" || (wget -nc --no-check-certificate \"http://artelab.dista.uninsubria.it/downloads/datasets/automatic_meter_reading/gas_meter_reading/gas_meter_reading.zip\" && unzip gas_meter_reading -d .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f567bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from sap_computer_vision.datasets import pascal_voc_style as pvs\n",
    "\n",
    "dataset_folder  = pathlib.Path('MeterDataset/Rough-Digit-Classification/')\n",
    "\n",
    "d, c = pvs.split_and_register('dataset',\n",
    "                              img_dir=dataset_folder / 'JPEGImages',\n",
    "                              xml_dir=dataset_folder / 'Annotations',\n",
    "                              splits={'train': 0.8,\n",
    "                                      'test': 0.1,\n",
    "                                      'validation': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8842d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in d.items():\n",
    "    print(f'{k} {len(v)} examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b441c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from sap_computer_vision import setup_loggers, get_cfg, get_config_file\n",
    "import numpy as np\n",
    "\n",
    "out_dir = 'object_detecion_model_modified_loader'\n",
    "if pathlib.Path(out_dir).exists():\n",
    "    shutil.rmtree(out_dir)\n",
    "    #raise RuntimeError('Result folder already exists. Please delete the folder or change the name of the output')\n",
    "\n",
    "setup_loggers(out_dir)\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(get_config_file('Base-EarlyStopping'))\n",
    "cfg.merge_from_file(get_config_file('Base-Evaluation'))\n",
    "cfg.merge_from_file(get_config_file('COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml'))\n",
    "\n",
    "cfg.SOLVER.MAX_ITER = 100\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.GAMMA = float(np.sqrt(0.1))\n",
    "cfg.SOLVER.EARLY_STOPPING.ENABLED = False\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = max(int(0.01 * cfg.SOLVER.MAX_ITER), 50)\n",
    "cfg.SOLVER.STEPS = [cfg.SOLVER.MAX_ITER * p for p in (0.05, 0.25, 0.375, 0.5, 0.75, 0.9)]\n",
    "for aug in ['RANDOM_LIGHTING', 'RANDOM_BRIGHTNESS', 'RANDOM_SATURATION', 'RANDOM_CONTRAST', 'CROP', 'RANDOM_ROTATION']:\n",
    "    if cfg.INPUT.get(aug, None) is not None:\n",
    "        cfg.INPUT[aug].ENABLED = True\n",
    "\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\"\n",
    "        \n",
    "     \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(c)\n",
    "        \n",
    "\n",
    "cfg.OUTPUT_DIR = out_dir\n",
    "cfg.DATASETS.TRAIN = ('dataset_train', )\n",
    "cfg.DATASETS.TEST = ('dataset_validation', )\n",
    "\n",
    "# Adjust to hardware\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8 \n",
    "cfg.SOLVER.IMS_PER_BATCH_EVAL = 12\n",
    "cfg.DATALOADER.NUM_WORKERS = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 250\n",
    "\n",
    "\n",
    "# Add new Option for the custom Dataloader\n",
    "from detectron2.config import CfgNode\n",
    "cfg.METER_READING = CfgNode({})\n",
    "cfg.METER_READING.DIGIT_REPLACE_PROB_TRAIN = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.SOLVER.EARLY_STOPPING.ENABLED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76aafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = pathlib.Path(out_dir)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "with (out_dir / 'used_config.yaml').open('w') as stream:\n",
    "    stream.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sap_computer_vision.engine import ObjectDetectionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "from typing import List, Optional, Union, Dict\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from detectron2.data.build import get_detection_dataset_dicts\n",
    "from detectron2.config import configurable\n",
    "\n",
    "from sap_computer_vision.data.data_build import DatasetMapperWithAdditionalAugmentaions\n",
    "from detectron2.data.build import build_detection_train_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.structures.boxes import pairwise_iou, BoxMode\n",
    "\n",
    "\n",
    "def cut_and_paste(img_src, img_dest, anno_src, anno_dest, image_format):\n",
    "    anno_dest['category_id'] = anno_src['category_id']\n",
    "    bbox_src = BoxMode.convert(anno_src['bbox'], anno_src['bbox_mode'], BoxMode.XYXY_ABS)\n",
    "    _, _, w_dest, h_dest = BoxMode.convert(anno_dest['bbox'], anno_dest['bbox_mode'], BoxMode.XYWH_ABS)\n",
    "    bbox_dest = BoxMode.convert(anno_dest['bbox'], anno_dest['bbox_mode'], BoxMode.XYXY_ABS)\n",
    "    bbox_src, bbox_dest = [int(x) for x in bbox_src], [int(x) for x in bbox_dest]\n",
    "    region = img_src.crop(bbox_src).resize((int(w_dest), int(h_dest)))\n",
    "    img_dest.paste(region, bbox_dest)\n",
    "    return img_dest\n",
    "\n",
    "\n",
    "class DatasetMapperPatchwork(DatasetMapperWithAdditionalAugmentaions):\n",
    "    \n",
    "    @configurable\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        dataset_dicts: List[Dict] = {},\n",
    "        digit_replace_prob: float = 0.2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.dataset_dicts = dataset_dicts\n",
    "        self.digit_replace_prob = digit_replace_prob\n",
    "        ret = super().__init__.__wrapped__(self, *args, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls,\n",
    "                    cfg,\n",
    "                    is_train: bool=True,\n",
    "                    digit_replace_prob: float = 0.2,\n",
    "                    additional_augs_orignal_image=None,\n",
    "                    additional_augs_resized_image=None):\n",
    "        ret = DatasetMapperWithAdditionalAugmentaions.from_config(\n",
    "            cfg,\n",
    "            is_train,\n",
    "            additional_augs_orignal_image=additional_augs_orignal_image,\n",
    "            additional_augs_resized_image=additional_augs_resized_image\n",
    "        )\n",
    "        if is_train:\n",
    "            ret['dataset_dicts'] = get_detection_dataset_dicts(cfg.DATASETS.TRAIN)\n",
    "        else:\n",
    "            ret['dataset_dicts'] = get_detection_dataset_dicts(cfg.DATASETS.TEST)\n",
    "        ret['digit_replace_prob'] = digit_replace_prob\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    def load_and_patch_image(self, dataset_dict, image_format):\n",
    "        new_dataset_dict = copy.deepcopy(dataset_dict)\n",
    "        image = Image.open(new_dataset_dict[\"file_name\"])\n",
    "        for i, a in enumerate(new_dataset_dict['annotations']):\n",
    "            if np.random.uniform() > self.digit_replace_prob:\n",
    "                continue\n",
    "            source = np.random.choice(self.dataset_dicts)\n",
    "            source_image = Image.open(source[\"file_name\"])\n",
    "            new_anno = np.random.choice(source['annotations'])\n",
    "            image = cut_and_paste(source_image, image, new_anno, a, self.image_format)\n",
    "        img_dest = utils.convert_PIL_to_numpy(image, format=image_format)\n",
    "        return img_dest, new_dataset_dict\n",
    "    \n",
    "    \n",
    "    def __call__(self, dataset_dict):\n",
    "        \"\"\"\n",
    "        Code copied from: https://github.com/facebookresearch/detectron2/blob/main/detectron2/data/dataset_mapper.py\n",
    "        \"\"\"\n",
    "        image, dataset_dict = self.load_and_patch_image(dataset_dict, self.image_format)\n",
    "        utils.check_image_size(dataset_dict, image)\n",
    "        # USER: Remove if you don't do semantic/panoptic segmentation.\n",
    "        if \"sem_seg_file_name\" in dataset_dict:\n",
    "            sem_seg_gt = utils.read_image(dataset_dict.pop(\"sem_seg_file_name\"), \"L\").squeeze(2)\n",
    "        else:\n",
    "            sem_seg_gt = None\n",
    "        \n",
    "        aug_input = T.AugInput(image, sem_seg=sem_seg_gt)\n",
    "        transforms = self.augmentations(aug_input)\n",
    "        image, sem_seg_gt = aug_input.image, aug_input.sem_seg\n",
    "\n",
    "        image_shape = image.shape[:2]\n",
    "        dataset_dict[\"image\"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))\n",
    "        if sem_seg_gt is not None:\n",
    "            dataset_dict[\"sem_seg\"] = torch.as_tensor(sem_seg_gt.astype(\"long\"))\n",
    "\n",
    "        if self.proposal_topk is not None:\n",
    "            utils.transform_proposals(\n",
    "                dataset_dict, image_shape, transforms, proposal_topk=self.proposal_topk\n",
    "            )\n",
    "\n",
    "        if not self.is_train:\n",
    "            dataset_dict.pop(\"annotations\", None)\n",
    "            dataset_dict.pop(\"sem_seg_file_name\", None)\n",
    "            return dataset_dict\n",
    "        \n",
    "        if \"annotations\" in dataset_dict:\n",
    "            self._transform_annotations(dataset_dict, transforms, image_shape)\n",
    "\n",
    "        return dataset_dict\n",
    "    \n",
    "\n",
    "    \n",
    "class ObjectDetectionTrainerPatchedImages(ObjectDetectionTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        additional_augs_orignal_image = []\n",
    "        additional_augs_resized_image = []\n",
    "        mapper = DatasetMapperPatchwork(\n",
    "            cfg,\n",
    "            is_train=True,\n",
    "            digit_replace_prob=cfg.METER_READING.DIGIT_REPLACE_PROB_TRAIN)\n",
    "        return build_detection_train_loader(cfg, mapper=mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "mapper = DatasetMapperPatchwork(cfg, is_train=True, digit_replace_prob=0.4)\n",
    "random_example = np.random.choice(mapper.dataset_dicts)\n",
    "mapped_example = mapper(random_example)\n",
    "rgb_numpy_img = utils.convert_image_to_rgb(np.transpose(mapped_example['image'].numpy(), (1, 2, 0)), cfg.INPUT.FORMAT)\n",
    "plt.imshow(rgb_numpy_img)\n",
    "print(mapped_example['instances'].gt_classes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7431f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer = ObjectDetectionTrainerPatchedImages(cfg)\n",
    "trainer.resume_or_load(resume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e539fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "dl = trainer.build_test_loader(cfg, cfg.DATASETS.TEST)\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sap_computer_vision.utils.object_detection import torchvision_nms_on_model_output\n",
    "\n",
    "iou_threshold = 0.5\n",
    "\n",
    "\n",
    "results = []\n",
    "for batch in dl:\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        results_batch = trainer.model(batch)\n",
    "        results_batch = torchvision_nms_on_model_output(results_batch, iou_threshold, device='cpu')\n",
    "        for i in batch: # remove loaded image for smaller results\n",
    "            del i['image']\n",
    "        results.extend([{**i, **o} for i, o in zip(batch, results_batch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.detection_utils import read_image\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "resuld_idx = np.random.choice([*range(len(results))])\n",
    "vis = Visualizer(img_rgb=read_image(results[resuld_idx]['file_name']), metadata=metadata)\n",
    "vis.draw_instance_predictions(results[resuld_idx]['instances']).fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
